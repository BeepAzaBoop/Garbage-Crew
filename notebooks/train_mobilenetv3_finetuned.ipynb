{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/multi-class-garbage-classification.zip\"\n",
        "extract_path = \"/content/multi-class-garbage-classification\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "TBAu5ScNFppC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade torch"
      ],
      "metadata": {
        "id": "LUmKzheJHx3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "p2KXONxA7O01"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "data_dir = \"/content/multi-class-garbage-classification/content/multi-class-garbage-classification\"\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load dataset using ImageFolder\n",
        "dataset = datasets.ImageFolder(root=data_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "targets = [sample[1] for sample in dataset.samples]\n",
        "\n",
        "train_idx, val_idx = train_test_split(\n",
        "    range(len(dataset)), test_size=0.2, stratify=targets, random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = Subset(dataset, train_idx)\n",
        "val_dataset = Subset(dataset, val_idx)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "ITp0FVm47rUX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = torch.load(\"/content/mobilenetv3_garbage_classifier.pt\", weights_only=False)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "1TgFoMz-7S0y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "YIwIHcgC8j9N"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # --- Training ---\n",
        "    model.train()\n",
        "    train_loss, train_correct, train_total = 0.0, 0, 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, preds = outputs.max(1)\n",
        "        train_correct += (preds == labels).sum().item()\n",
        "        train_total += labels.size(0)\n",
        "\n",
        "    train_acc = 100 * train_correct / train_total\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    # --- Validation ---\n",
        "    model.eval()\n",
        "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, preds = outputs.max(1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    val_acc = 100 * val_correct / val_total\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    # --- Print Epoch Summary ---\n",
        "    print(\n",
        "        f\"Epoch {epoch+1}: \"\n",
        "        f\"Train Loss = {avg_train_loss:.4f} | Train Acc = {train_acc:.2f}% || \"\n",
        "        f\"Val Loss = {avg_val_loss:.4f} | Val Acc = {val_acc:.2f}%\"\n",
        "    )"
      ],
      "metadata": {
        "id": "4QtMd7la-3ym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5395ae52-ef53-4483-f6dc-c955660635a5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Train]: 100%|██████████| 150/150 [00:25<00:00,  6.00it/s]\n",
            "Epoch 1/10 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 1.9617 | Train Acc = 59.79% || Val Loss = 0.4065 | Val Acc = 85.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 [Train]: 100%|██████████| 150/150 [00:25<00:00,  5.89it/s]\n",
            "Epoch 2/10 [Val]: 100%|██████████| 38/38 [00:03<00:00, 10.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss = 0.2639 | Train Acc = 91.33% || Val Loss = 0.2190 | Val Acc = 93.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10 [Train]: 100%|██████████| 150/150 [00:26<00:00,  5.70it/s]\n",
            "Epoch 3/10 [Val]: 100%|██████████| 38/38 [00:03<00:00,  9.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss = 0.1110 | Train Acc = 96.71% || Val Loss = 0.1749 | Val Acc = 93.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10 [Train]: 100%|██████████| 150/150 [00:24<00:00,  6.01it/s]\n",
            "Epoch 4/10 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss = 0.0584 | Train Acc = 98.40% || Val Loss = 0.1730 | Val Acc = 94.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10 [Train]: 100%|██████████| 150/150 [00:25<00:00,  5.80it/s]\n",
            "Epoch 5/10 [Val]: 100%|██████████| 38/38 [00:03<00:00, 10.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss = 0.0291 | Train Acc = 99.35% || Val Loss = 0.1555 | Val Acc = 95.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10 [Train]: 100%|██████████| 150/150 [00:24<00:00,  6.04it/s]\n",
            "Epoch 6/10 [Val]: 100%|██████████| 38/38 [00:03<00:00,  9.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss = 0.0273 | Train Acc = 99.17% || Val Loss = 0.1526 | Val Acc = 95.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10 [Train]: 100%|██████████| 150/150 [00:24<00:00,  6.08it/s]\n",
            "Epoch 7/10 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss = 0.0219 | Train Acc = 99.50% || Val Loss = 0.1507 | Val Acc = 96.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10 [Train]: 100%|██████████| 150/150 [00:24<00:00,  6.05it/s]\n",
            "Epoch 8/10 [Val]: 100%|██████████| 38/38 [00:03<00:00, 10.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Loss = 0.0161 | Train Acc = 99.60% || Val Loss = 0.1685 | Val Acc = 95.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10 [Train]: 100%|██████████| 150/150 [00:24<00:00,  6.05it/s]\n",
            "Epoch 9/10 [Val]: 100%|██████████| 38/38 [00:03<00:00, 10.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss = 0.0106 | Train Acc = 99.71% || Val Loss = 0.1581 | Val Acc = 96.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10 [Train]: 100%|██████████| 150/150 [00:24<00:00,  6.08it/s]\n",
            "Epoch 10/10 [Val]: 100%|██████████| 38/38 [00:04<00:00,  8.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss = 0.0085 | Train Acc = 99.77% || Val Loss = 0.1838 | Val Acc = 95.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Generate report\n",
        "target_names = dataset.classes  # from ImageFolder — maps class indices to names\n",
        "report = classification_report(all_labels, all_preds, target_names=target_names, digits=3)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "fysr9QehhHUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb266de-be5e-4c9a-b540-b3e00c5d6085"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          glass      0.944     0.935     0.940       200\n",
            "          metal      0.945     0.945     0.945       200\n",
            "  organic_waste      0.985     0.990     0.988       200\n",
            "paper_cardboard      0.985     0.980     0.982       200\n",
            "        plastic      0.957     0.900     0.928       200\n",
            "          trash      0.921     0.985     0.952       200\n",
            "\n",
            "       accuracy                          0.956      1200\n",
            "      macro avg      0.956     0.956     0.956      1200\n",
            "   weighted avg      0.956     0.956     0.956      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"/content/mobilenetv3_garbage_classifier_2.pt\")"
      ],
      "metadata": {
        "id": "ik-z38BOhI_r"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}